{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae7fdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Load Saumya's Model\n",
    "# ✅ Load the saved TensorFlow 2 model\n",
    "saumyamodel_path = Path (r\"E:\\ArtifactRemovalProject\\Saumya NNArtifact\\saved_model\\NNArtifact_tf2\")\n",
    "saumyamodel = tf.saved_model.load(saumyamodel_path)\n",
    "\n",
    "si = np.load(r\"E:\\ArtifactRemovalProject\\data\\modelinference\\DOSEESC_EM09\\11.20.2018\\si.npy\")\n",
    "\n",
    "num_classes = 2\n",
    "num_slices = si.shape[0] #32\n",
    "x_size = si.shape[1] #64\n",
    "y_size = si.shape[2] #64\n",
    "spectra_size = si.shape[3] #512\n",
    "\n",
    "BATCH_SIZE = x_size * y_size\n",
    "\n",
    "ypred_array = np.zeros((num_slices, x_size, y_size, num_classes)) # 32,64,64,2\n",
    "\n",
    "# ✅ Run inference using the loaded model\n",
    "for z_slice in range(num_slices):\n",
    "    print(z_slice)\n",
    "    xtest = np.real(si[z_slice])\n",
    "    xtest = xtest.reshape(x_size*y_size, spectra_size) #4096x512\n",
    "\n",
    "    ypred_array[z_slice] = np.asarray(tf.nn.softmax(saumyamodel.predict(xtest))).reshape(x_size, y_size, num_classes)\n",
    "\n",
    "# ── 10) Cleanup ────────────────────────────────────────────────────────────\n",
    "del saumyamodel\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Load My Model\n",
    "# ── 1) Load your config to get model settings ───────────────────────────────\n",
    "base_dir    = Path.cwd().parent\n",
    "ensemble_cfg_path = base_dir / \"results\" / \"ensembles\" / \"config.json\"\n",
    "\n",
    "with open(ensemble_cfg_path, \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# Choose which ensemble to apply (e.g. 'fits_combined', 'fits+water', 'all_four')\n",
    "exp_key = \"all_four\"  # or any key present in your config\n",
    "info    = cfg[exp_key]\n",
    "\n",
    "# ── 2) Load your saved ensemble model ───────────────────────────────────────\n",
    "model = tf.keras.models.load_model(info[\"model_path\"])\n",
    "print(f\"{exp_key} Model Loaded\")\n",
    "\n",
    "# ── 3) Load the spatial-spectral data ───────────────────────────────────────\n",
    "water = np.load(r\"E:\\ArtifactRemovalProject\\data\\modelinference\\DOSEESC_EM09\\11.20.2018\\siref.npy\")\n",
    "fit1 = np.load(r\"E:\\ArtifactRemovalProject\\data\\modelinference\\DOSEESC_EM09\\11.20.2018\\midasfit.npy\")\n",
    "fit2    = np.load(r\"E:\\ArtifactRemovalProject\\data\\modelinference\\DOSEESC_EM09\\11.20.2018\\nnfit.npy\")\n",
    "\n",
    "num_slices, H, W, S = fit1.shape  # (32,64,64,512)\n",
    "\n",
    "# ── 4) Flatten spatial dims for vectorized preprocessing ───────────────────\n",
    "raw = si.reshape(-1, S)\n",
    "water = water.reshape(-1, S) # shape (N,512)\n",
    "fit1 = fit1.reshape(-1, S) # shape (N,512)\n",
    "fit2   = fit2.reshape(-1, S)     # shape (N,512)\n",
    "\n",
    "# 4a) z-score normalization function\n",
    "def zscore_per_spectrum(x, eps=1e-6):\n",
    "    mu  = x.mean(axis=1, keepdims=True)\n",
    "    std = x.std(axis=1, keepdims=True) + eps\n",
    "    return (x - mu) / std\n",
    "\n",
    "# 4b) normalize each channel\n",
    "raw = zscore_per_spectrum(raw)\n",
    "fit1   = zscore_per_spectrum(fit1)\n",
    "fit2   = zscore_per_spectrum(fit2)\n",
    "\n",
    "# uncomment for water\n",
    "wat_log = np.log10(np.abs(water) + 1e-6)\n",
    "wmin    = wat_log.min(axis=1, keepdims=True)\n",
    "wmax    = wat_log.max(axis=1, keepdims=True) + 1e-6\n",
    "water = (wat_log - wmin) / (wmax - wmin)\n",
    "\n",
    "# ── 5) Build model input tensor ────────────────────────────────────────────\n",
    "# Channels order from config, e.g. [\"raw\",\"water\"]\n",
    "channels = info[\"channels\"]\n",
    "# Stack in the correct order\n",
    "channel_arrays = {\n",
    "    \"raw\": raw,\n",
    "    \"water\": water,\n",
    "    \"fit1\": fit1,\n",
    "    \"fit2\": fit2\n",
    "    # add \"fit1 - midas\" and \"fit2 - nnfit\" if needed and loaded\n",
    "}\n",
    "# concatenate into shape (N, 512, n_ch)\n",
    "X = np.stack([channel_arrays[ch] for ch in channels], axis=-1).astype(\"float32\")\n",
    "\n",
    "# ── 6) Run inference ────────────────────────────────────────────────────────\n",
    "probs = model.predict(X, batch_size=4096).ravel()\n",
    "\n",
    "# ──  Cleanup ────────────────────────────────────────────────────────────\n",
    "del model\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# ── 7) Threshold predictions ───────────────────────────────────────────────\n",
    "thr   = info[\"threshold\"]\n",
    "preds = (probs >= thr).astype(int)\n",
    "\n",
    "# ── 8) Reshape back to spatial volume ───────────────────────────────────────\n",
    "probs_vol = probs.reshape(num_slices, H, W)\n",
    "preds_vol = preds.reshape(num_slices, H, W)\n",
    "\n",
    "preds_vol = preds_vol ^ 1\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
